# Training-specific configuration
# This file overrides defaults from default.yaml

# Model hyperparameters for training
model:
  hidden_dim: 256
  num_layers: 3
  num_heads: 4
  concat_heads: false
  dropout: 0.2
  layer_norm: true
  pooling_type: 'attention' # Use attention pooling
  attention_hidden: 128
  attention_dropout: 0.1

# Training parameters
training:
  batch_size: 8
  num_epochs: 200
  pretrain_epochs: 50

  # Optimizer
  learning_rate: 0.001
  weight_decay: 0.0001

  # Learning rate schedule
  scheduler: 'reduce_on_plateau'
  patience: 10
  factor: 0.5
  min_lr: 1.0e-6

  # Negative sampling
  neg_sample_ratio: 5

  # Validation
  val_split: 0.2
  val_frequency: 1

  # Early stopping
  early_stopping_patience: 20
  min_delta: 0.0001

  # Gradient clipping
  gradient_clip: 1.0

# Loss configuration
losses:
  feature_recon: 1.0
  edge_recon: 1.0
  consistency: 0.5
  entropy_reg: 0.1
  contrastive: 0.0 # Disabled by default

# Logging configuration
logging:
  log_dir: 'outputs/logs/'
  log_frequency: 10
  save_attention_weights: true
  save_embeddings: true
  tensorboard: true

# Checkpoint configuration
checkpoint:
  save_dir: 'outputs/checkpoints/'
  save_best_only: false
  save_frequency: 10
  max_checkpoints: 5
